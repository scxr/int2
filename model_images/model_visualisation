digraph {
	graph [size="64.35,64.35"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	1713547057888 [label="
 (1, 102)" fillcolor=darkolivegreen1]
	1713504542480 [label=AddmmBackward0]
	1713504542288 -> 1713504542480
	1711909199680 [label="fc.bias
 (102)" fillcolor=lightblue]
	1711909199680 -> 1713504542288
	1713504542288 [label=AccumulateGrad]
	1713504542576 -> 1713504542480
	1713504542576 [label=ViewBackward0]
	1713504542624 -> 1713504542576
	1713504542624 [label=MeanBackward1]
	1713504542144 -> 1713504542624
	1713504542144 [label=ReluBackward0]
	1713504542048 -> 1713504542144
	1713504542048 [label=AddBackward0]
	1713504541856 -> 1713504542048
	1713504541856 [label=CudnnBatchNormBackward0]
	1713504541712 -> 1713504541856
	1713504541712 [label=ConvolutionBackward0]
	1711909084944 -> 1713504541712
	1711909084944 [label=ReluBackward0]
	1713547026640 -> 1711909084944
	1713547026640 [label=CudnnBatchNormBackward0]
	1713547026736 -> 1713547026640
	1713547026736 [label=ConvolutionBackward0]
	1713504542000 -> 1713547026736
	1713504542000 [label=ReluBackward0]
	1713547027024 -> 1713504542000
	1713547027024 [label=AddBackward0]
	1713547027120 -> 1713547027024
	1713547027120 [label=CudnnBatchNormBackward0]
	1713547027264 -> 1713547027120
	1713547027264 [label=ConvolutionBackward0]
	1713547027456 -> 1713547027264
	1713547027456 [label=ReluBackward0]
	1713547027648 -> 1713547027456
	1713547027648 [label=CudnnBatchNormBackward0]
	1713547027744 -> 1713547027648
	1713547027744 [label=ConvolutionBackward0]
	1713547027936 -> 1713547027744
	1713547027936 [label=ReluBackward0]
	1713547028080 -> 1713547027936
	1713547028080 [label=AddBackward0]
	1713547028176 -> 1713547028080
	1713547028176 [label=CudnnBatchNormBackward0]
	1713547028320 -> 1713547028176
	1713547028320 [label=ConvolutionBackward0]
	1713547028512 -> 1713547028320
	1713547028512 [label=ReluBackward0]
	1713547028704 -> 1713547028512
	1713547028704 [label=CudnnBatchNormBackward0]
	1713547028800 -> 1713547028704
	1713547028800 [label=ConvolutionBackward0]
	1713547028128 -> 1713547028800
	1713547028128 [label=ReluBackward0]
	1713547029088 -> 1713547028128
	1713547029088 [label=AddBackward0]
	1713547029184 -> 1713547029088
	1713547029184 [label=CudnnBatchNormBackward0]
	1713547029328 -> 1713547029184
	1713547029328 [label=ConvolutionBackward0]
	1713547029520 -> 1713547029328
	1713547029520 [label=ReluBackward0]
	1713547029712 -> 1713547029520
	1713547029712 [label=CudnnBatchNormBackward0]
	1713547029808 -> 1713547029712
	1713547029808 [label=ConvolutionBackward0]
	1713547030000 -> 1713547029808
	1713547030000 [label=ReluBackward0]
	1713547030144 -> 1713547030000
	1713547030144 [label=AddBackward0]
	1713547030240 -> 1713547030144
	1713547030240 [label=CudnnBatchNormBackward0]
	1713547030384 -> 1713547030240
	1713547030384 [label=ConvolutionBackward0]
	1713547030480 -> 1713547030384
	1713547030480 [label=ReluBackward0]
	1713546961200 -> 1713547030480
	1713546961200 [label=CudnnBatchNormBackward0]
	1713546961296 -> 1713546961200
	1713546961296 [label=ConvolutionBackward0]
	1713547030192 -> 1713546961296
	1713547030192 [label=ReluBackward0]
	1713546961584 -> 1713547030192
	1713546961584 [label=AddBackward0]
	1713546961680 -> 1713546961584
	1713546961680 [label=CudnnBatchNormBackward0]
	1713546961824 -> 1713546961680
	1713546961824 [label=ConvolutionBackward0]
	1713546962016 -> 1713546961824
	1713546962016 [label=ReluBackward0]
	1713546962208 -> 1713546962016
	1713546962208 [label=CudnnBatchNormBackward0]
	1713546962304 -> 1713546962208
	1713546962304 [label=ConvolutionBackward0]
	1713546962496 -> 1713546962304
	1713546962496 [label=ReluBackward0]
	1713546962640 -> 1713546962496
	1713546962640 [label=AddBackward0]
	1713546962736 -> 1713546962640
	1713546962736 [label=CudnnBatchNormBackward0]
	1713546962880 -> 1713546962736
	1713546962880 [label=ConvolutionBackward0]
	1713546963072 -> 1713546962880
	1713546963072 [label=ReluBackward0]
	1713546963264 -> 1713546963072
	1713546963264 [label=CudnnBatchNormBackward0]
	1713546963360 -> 1713546963264
	1713546963360 [label=ConvolutionBackward0]
	1713546962688 -> 1713546963360
	1713546962688 [label=ReluBackward0]
	1713546963648 -> 1713546962688
	1713546963648 [label=AddBackward0]
	1713546963744 -> 1713546963648
	1713546963744 [label=CudnnBatchNormBackward0]
	1713546963888 -> 1713546963744
	1713546963888 [label=ConvolutionBackward0]
	1713546964080 -> 1713546963888
	1713546964080 [label=ReluBackward0]
	1713546964272 -> 1713546964080
	1713546964272 [label=CudnnBatchNormBackward0]
	1713546964368 -> 1713546964272
	1713546964368 [label=ConvolutionBackward0]
	1713546963696 -> 1713546964368
	1713546963696 [label=MaxPool2DWithIndicesBackward0]
	1713546964656 -> 1713546963696
	1713546964656 [label=ReluBackward0]
	1713546964752 -> 1713546964656
	1713546964752 [label=CudnnBatchNormBackward0]
	1713546964848 -> 1713546964752
	1713546964848 [label=ConvolutionBackward0]
	1713546964944 -> 1713546964848
	1711909272768 [label="conv1.0.weight
 (64, 3, 7, 7)" fillcolor=lightblue]
	1711909272768 -> 1713546964944
	1713546964944 [label=AccumulateGrad]
	1713546964800 -> 1713546964752
	1713049073840 [label="conv1.1.weight
 (64)" fillcolor=lightblue]
	1713049073840 -> 1713546964800
	1713546964800 [label=AccumulateGrad]
	1713546964464 -> 1713546964752
	1713049073280 [label="conv1.1.bias
 (64)" fillcolor=lightblue]
	1713049073280 -> 1713546964464
	1713546964464 [label=AccumulateGrad]
	1713546964560 -> 1713546964368
	1711909273088 [label="layer0.0.conv1.0.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	1711909273088 -> 1713546964560
	1713546964560 [label=AccumulateGrad]
	1713546964320 -> 1713546964272
	1711909273008 [label="layer0.0.conv1.1.weight
 (64)" fillcolor=lightblue]
	1711909273008 -> 1713546964320
	1713546964320 [label=AccumulateGrad]
	1713546964176 -> 1713546964272
	1711909273168 [label="layer0.0.conv1.1.bias
 (64)" fillcolor=lightblue]
	1711909273168 -> 1713546964176
	1713546964176 [label=AccumulateGrad]
	1713546964032 -> 1713546963888
	1711909253184 [label="layer0.0.conv2.0.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	1711909253184 -> 1713546964032
	1713546964032 [label=AccumulateGrad]
	1713546963984 -> 1713546963888
	1711909253264 [label="layer0.0.conv2.0.bias
 (64)" fillcolor=lightblue]
	1711909253264 -> 1713546963984
	1713546963984 [label=AccumulateGrad]
	1713546963840 -> 1713546963744
	1711909273488 [label="layer0.0.conv2.1.weight
 (64)" fillcolor=lightblue]
	1711909273488 -> 1713546963840
	1713546963840 [label=AccumulateGrad]
	1713546963792 -> 1713546963744
	1711909253344 [label="layer0.0.conv2.1.bias
 (64)" fillcolor=lightblue]
	1711909253344 -> 1713546963792
	1713546963792 [label=AccumulateGrad]
	1713546963696 -> 1713546963648
	1713546963552 -> 1713546963360
	1711909253904 [label="layer0.1.conv1.0.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	1711909253904 -> 1713546963552
	1713546963552 [label=AccumulateGrad]
	1713546963312 -> 1713546963264
	1711909253984 [label="layer0.1.conv1.1.weight
 (64)" fillcolor=lightblue]
	1711909253984 -> 1713546963312
	1713546963312 [label=AccumulateGrad]
	1713546963168 -> 1713546963264
	1711909254064 [label="layer0.1.conv1.1.bias
 (64)" fillcolor=lightblue]
	1711909254064 -> 1713546963168
	1713546963168 [label=AccumulateGrad]
	1713546963024 -> 1713546962880
	1711909254624 [label="layer0.1.conv2.0.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	1711909254624 -> 1713546963024
	1713546963024 [label=AccumulateGrad]
	1713546962976 -> 1713546962880
	1711909254784 [label="layer0.1.conv2.0.bias
 (64)" fillcolor=lightblue]
	1711909254784 -> 1713546962976
	1713546962976 [label=AccumulateGrad]
	1713546962832 -> 1713546962736
	1711909254944 [label="layer0.1.conv2.1.weight
 (64)" fillcolor=lightblue]
	1711909254944 -> 1713546962832
	1713546962832 [label=AccumulateGrad]
	1713546962784 -> 1713546962736
	1711909255024 [label="layer0.1.conv2.1.bias
 (64)" fillcolor=lightblue]
	1711909255024 -> 1713546962784
	1713546962784 [label=AccumulateGrad]
	1713546962688 -> 1713546962640
	1713546962448 -> 1713546962304
	1711909255984 [label="layer1.0.conv1.0.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	1711909255984 -> 1713546962448
	1713546962448 [label=AccumulateGrad]
	1713546962256 -> 1713546962208
	1711909256064 [label="layer1.0.conv1.1.weight
 (128)" fillcolor=lightblue]
	1711909256064 -> 1713546962256
	1713546962256 [label=AccumulateGrad]
	1713546962112 -> 1713546962208
	1711909256144 [label="layer1.0.conv1.1.bias
 (128)" fillcolor=lightblue]
	1711909256144 -> 1713546962112
	1713546962112 [label=AccumulateGrad]
	1713546961968 -> 1713546961824
	1711909256544 [label="layer1.0.conv2.0.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	1711909256544 -> 1713546961968
	1713546961968 [label=AccumulateGrad]
	1713546961920 -> 1713546961824
	1711909256624 [label="layer1.0.conv2.0.bias
 (128)" fillcolor=lightblue]
	1711909256624 -> 1713546961920
	1713546961920 [label=AccumulateGrad]
	1713546961776 -> 1713546961680
	1711909256704 [label="layer1.0.conv2.1.weight
 (128)" fillcolor=lightblue]
	1711909256704 -> 1713546961776
	1713546961776 [label=AccumulateGrad]
	1713546961728 -> 1713546961680
	1711909256784 [label="layer1.0.conv2.1.bias
 (128)" fillcolor=lightblue]
	1711909256784 -> 1713546961728
	1713546961728 [label=AccumulateGrad]
	1713546961632 -> 1713546961584
	1713546961632 [label=CudnnBatchNormBackward0]
	1713546962160 -> 1713546961632
	1713546962160 [label=ConvolutionBackward0]
	1713546962496 -> 1713546962160
	1713546962544 -> 1713546962160
	1711909255504 [label="layer1.0.downsample.0.weight
 (128, 64, 1, 1)" fillcolor=lightblue]
	1711909255504 -> 1713546962544
	1713546962544 [label=AccumulateGrad]
	1713546962064 -> 1713546961632
	1711909255424 [label="layer1.0.downsample.1.weight
 (128)" fillcolor=lightblue]
	1711909255424 -> 1713546962064
	1713546962064 [label=AccumulateGrad]
	1713546961872 -> 1713546961632
	1711909255584 [label="layer1.0.downsample.1.bias
 (128)" fillcolor=lightblue]
	1711909255584 -> 1713546961872
	1713546961872 [label=AccumulateGrad]
	1713546961488 -> 1713546961296
	1711909228848 [label="layer1.1.conv1.0.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	1711909228848 -> 1713546961488
	1713546961488 [label=AccumulateGrad]
	1713546961248 -> 1713546961200
	1711909228768 [label="layer1.1.conv1.1.weight
 (128)" fillcolor=lightblue]
	1711909228768 -> 1713546961248
	1713546961248 [label=AccumulateGrad]
	1713546961104 -> 1713546961200
	1711909228928 [label="layer1.1.conv1.1.bias
 (128)" fillcolor=lightblue]
	1711909228928 -> 1713546961104
	1713546961104 [label=AccumulateGrad]
	1713546961008 -> 1713547030384
	1711909229328 [label="layer1.1.conv2.0.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	1711909229328 -> 1713546961008
	1713546961008 [label=AccumulateGrad]
	1713546960960 -> 1713547030384
	1711909229408 [label="layer1.1.conv2.0.bias
 (128)" fillcolor=lightblue]
	1711909229408 -> 1713546960960
	1713546960960 [label=AccumulateGrad]
	1713547030336 -> 1713547030240
	1711909229488 [label="layer1.1.conv2.1.weight
 (128)" fillcolor=lightblue]
	1711909229488 -> 1713547030336
	1713547030336 [label=AccumulateGrad]
	1713547030288 -> 1713547030240
	1711909229568 [label="layer1.1.conv2.1.bias
 (128)" fillcolor=lightblue]
	1711909229568 -> 1713547030288
	1713547030288 [label=AccumulateGrad]
	1713547030192 -> 1713547030144
	1713547029952 -> 1713547029808
	1711909230848 [label="layer2.0.conv1.0.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	1711909230848 -> 1713547029952
	1713547029952 [label=AccumulateGrad]
	1713547029760 -> 1713547029712
	1711909231008 [label="layer2.0.conv1.1.weight
 (256)" fillcolor=lightblue]
	1711909231008 -> 1713547029760
	1713547029760 [label=AccumulateGrad]
	1713547029616 -> 1713547029712
	1711909230768 [label="layer2.0.conv1.1.bias
 (256)" fillcolor=lightblue]
	1711909230768 -> 1713547029616
	1713547029616 [label=AccumulateGrad]
	1713547029472 -> 1713547029328
	1711909231328 [label="layer2.0.conv2.0.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1711909231328 -> 1713547029472
	1713547029472 [label=AccumulateGrad]
	1713547029424 -> 1713547029328
	1711909231408 [label="layer2.0.conv2.0.bias
 (256)" fillcolor=lightblue]
	1711909231408 -> 1713547029424
	1713547029424 [label=AccumulateGrad]
	1713547029280 -> 1713547029184
	1711909231488 [label="layer2.0.conv2.1.weight
 (256)" fillcolor=lightblue]
	1711909231488 -> 1713547029280
	1713547029280 [label=AccumulateGrad]
	1713547029232 -> 1713547029184
	1711909231568 [label="layer2.0.conv2.1.bias
 (256)" fillcolor=lightblue]
	1711909231568 -> 1713547029232
	1713547029232 [label=AccumulateGrad]
	1713547029136 -> 1713547029088
	1713547029136 [label=CudnnBatchNormBackward0]
	1713547029664 -> 1713547029136
	1713547029664 [label=ConvolutionBackward0]
	1713547030000 -> 1713547029664
	1713547030048 -> 1713547029664
	1711909229968 [label="layer2.0.downsample.0.weight
 (256, 128, 1, 1)" fillcolor=lightblue]
	1711909229968 -> 1713547030048
	1713547030048 [label=AccumulateGrad]
	1713547029568 -> 1713547029136
	1711909230048 [label="layer2.0.downsample.1.weight
 (256)" fillcolor=lightblue]
	1711909230048 -> 1713547029568
	1713547029568 [label=AccumulateGrad]
	1713547029376 -> 1713547029136
	1711909230128 [label="layer2.0.downsample.1.bias
 (256)" fillcolor=lightblue]
	1711909230128 -> 1713547029376
	1713547029376 [label=AccumulateGrad]
	1713547028992 -> 1713547028800
	1711909231968 [label="layer2.1.conv1.0.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1711909231968 -> 1713547028992
	1713547028992 [label=AccumulateGrad]
	1713547028752 -> 1713547028704
	1711909232048 [label="layer2.1.conv1.1.weight
 (256)" fillcolor=lightblue]
	1711909232048 -> 1713547028752
	1713547028752 [label=AccumulateGrad]
	1713547028608 -> 1713547028704
	1711909232128 [label="layer2.1.conv1.1.bias
 (256)" fillcolor=lightblue]
	1711909232128 -> 1713547028608
	1713547028608 [label=AccumulateGrad]
	1713547028464 -> 1713547028320
	1711909232528 [label="layer2.1.conv2.0.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1711909232528 -> 1713547028464
	1713547028464 [label=AccumulateGrad]
	1713547028416 -> 1713547028320
	1711909195840 [label="layer2.1.conv2.0.bias
 (256)" fillcolor=lightblue]
	1711909195840 -> 1713547028416
	1713547028416 [label=AccumulateGrad]
	1713547028272 -> 1713547028176
	1711909195920 [label="layer2.1.conv2.1.weight
 (256)" fillcolor=lightblue]
	1711909195920 -> 1713547028272
	1713547028272 [label=AccumulateGrad]
	1713547028224 -> 1713547028176
	1711909196000 [label="layer2.1.conv2.1.bias
 (256)" fillcolor=lightblue]
	1711909196000 -> 1713547028224
	1713547028224 [label=AccumulateGrad]
	1713547028128 -> 1713547028080
	1713547027888 -> 1713547027744
	1711909197280 [label="layer3.0.conv1.0.weight
 (512, 256, 3, 3)" fillcolor=lightblue]
	1711909197280 -> 1713547027888
	1713547027888 [label=AccumulateGrad]
	1713547027696 -> 1713547027648
	1711909197360 [label="layer3.0.conv1.1.weight
 (512)" fillcolor=lightblue]
	1711909197360 -> 1713547027696
	1713547027696 [label=AccumulateGrad]
	1713547027552 -> 1713547027648
	1711909197440 [label="layer3.0.conv1.1.bias
 (512)" fillcolor=lightblue]
	1711909197440 -> 1713547027552
	1713547027552 [label=AccumulateGrad]
	1713547027408 -> 1713547027264
	1711909197840 [label="layer3.0.conv2.0.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	1711909197840 -> 1713547027408
	1713547027408 [label=AccumulateGrad]
	1713547027360 -> 1713547027264
	1711909197920 [label="layer3.0.conv2.0.bias
 (512)" fillcolor=lightblue]
	1711909197920 -> 1713547027360
	1713547027360 [label=AccumulateGrad]
	1713547027216 -> 1713547027120
	1711909198000 [label="layer3.0.conv2.1.weight
 (512)" fillcolor=lightblue]
	1711909198000 -> 1713547027216
	1713547027216 [label=AccumulateGrad]
	1713547027168 -> 1713547027120
	1711909198080 [label="layer3.0.conv2.1.bias
 (512)" fillcolor=lightblue]
	1711909198080 -> 1713547027168
	1713547027168 [label=AccumulateGrad]
	1713547027072 -> 1713547027024
	1713547027072 [label=CudnnBatchNormBackward0]
	1713547027600 -> 1713547027072
	1713547027600 [label=ConvolutionBackward0]
	1713547027936 -> 1713547027600
	1713547027984 -> 1713547027600
	1711909196400 [label="layer3.0.downsample.0.weight
 (512, 256, 1, 1)" fillcolor=lightblue]
	1711909196400 -> 1713547027984
	1713547027984 [label=AccumulateGrad]
	1713547027504 -> 1713547027072
	1711909196480 [label="layer3.0.downsample.1.weight
 (512)" fillcolor=lightblue]
	1711909196480 -> 1713547027504
	1713547027504 [label=AccumulateGrad]
	1713547027312 -> 1713547027072
	1711909196720 [label="layer3.0.downsample.1.bias
 (512)" fillcolor=lightblue]
	1711909196720 -> 1713547027312
	1713547027312 [label=AccumulateGrad]
	1713547026928 -> 1713547026736
	1711909198480 [label="layer3.1.conv1.0.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	1711909198480 -> 1713547026928
	1713547026928 [label=AccumulateGrad]
	1713547026688 -> 1713547026640
	1711909198560 [label="layer3.1.conv1.1.weight
 (512)" fillcolor=lightblue]
	1711909198560 -> 1713547026688
	1713547026688 [label=AccumulateGrad]
	1713547026544 -> 1713547026640
	1711909198640 [label="layer3.1.conv1.1.bias
 (512)" fillcolor=lightblue]
	1711909198640 -> 1713547026544
	1713547026544 [label=AccumulateGrad]
	1713504541520 -> 1713504541712
	1711909199040 [label="layer3.1.conv2.0.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	1711909199040 -> 1713504541520
	1713504541520 [label=AccumulateGrad]
	1713504541568 -> 1713504541712
	1711909199120 [label="layer3.1.conv2.0.bias
 (512)" fillcolor=lightblue]
	1711909199120 -> 1713504541568
	1713504541568 [label=AccumulateGrad]
	1713504541760 -> 1713504541856
	1711909199200 [label="layer3.1.conv2.1.weight
 (512)" fillcolor=lightblue]
	1711909199200 -> 1713504541760
	1713504541760 [label=AccumulateGrad]
	1713504541808 -> 1713504541856
	1711909199280 [label="layer3.1.conv2.1.bias
 (512)" fillcolor=lightblue]
	1711909199280 -> 1713504541808
	1713504541808 [label=AccumulateGrad]
	1713504542000 -> 1713504542048
	1713504542336 -> 1713504542480
	1713504542336 [label=TBackward0]
	1713504542096 -> 1713504542336
	1711909199600 [label="fc.weight
 (102, 512)" fillcolor=lightblue]
	1711909199600 -> 1713504542096
	1713504542096 [label=AccumulateGrad]
	1713504542480 -> 1713547057888
}
