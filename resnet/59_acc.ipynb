{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g_jvUfaq45FX","executionInfo":{"status":"ok","timestamp":1683398555978,"user_tz":-60,"elapsed":5948,"user":{"displayName":"Bailey Uniacke","userId":"03860064819488115762"}},"outputId":"7d8f3624-503c-4ad5-e8a4-cd1173c09671"},"outputs":[{"output_type":"stream","name":"stdout","text":["Running on cpu\n"]}],"source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torchvision import datasets\n","from torchvision import transforms\n","from torch.utils.data import DataLoader\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Running on {device}\")"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UDlZe3cH45Fa","executionInfo":{"status":"ok","timestamp":1683398577209,"user_tz":-60,"elapsed":21234,"user":{"displayName":"Bailey Uniacke","userId":"03860064819488115762"}},"outputId":"29e0c080-de86-4f94-e7e4-b52f71b65b53"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/102flowers.tgz to flowers/flowers-102/102flowers.tgz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 344862509/344862509 [00:03<00:00, 95641561.23it/s] \n"]},{"output_type":"stream","name":"stdout","text":["Extracting flowers/flowers-102/102flowers.tgz to flowers/flowers-102\n","Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/imagelabels.mat to flowers/flowers-102/imagelabels.mat\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 502/502 [00:00<00:00, 1209385.76it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/setid.mat to flowers/flowers-102/setid.mat\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 14989/14989 [00:00<00:00, 15237135.88it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Number of training examples: 1020\n","Number of test examples: 6149\n"]}],"source":["def data_loader(data, batch_size, random_seed=123, valid_size=0.1, shuffle=True,test=False):\n","    normalise = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","    transform = transforms.Compose([transforms.Resize((224,224)),transforms.ToTensor(),normalise])\n","    transform_train = transforms.Compose(\n","        [\n","        transforms.RandomRotation(5),\n","         transforms.RandomResizedCrop(224),\n","         transforms.RandomHorizontalFlip(),\n","         transforms.ToTensor(),\n","         normalise])\n","    if test:\n","        dataset = datasets.Flowers102(root=data, split=\"test\", download=True, transform=transform)\n","        data_loader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=shuffle)\n","        print(f\"Number of test examples: {len(dataset)}\")\n","        return data_loader\n","    train_dataset = datasets.Flowers102(root=data, split=\"train\", download=True, transform=transform_train)\n","    validation_dataset = datasets.Flowers102(root=data, split=\"val\", download=True, transform=transform)\n","    num_train = len(train_dataset)\n","    indices = list(range(num_train))\n","    split = int(np.floor(valid_size * num_train))\n","\n","    if shuffle:\n","        np.random.seed(random_seed)\n","        np.random.shuffle(indices)\n","    # train_idx, valid_idx = indices[split:], indices[:split]\n","    # train_sampler = torch.utils.data.sampler.SubsetRandomSampler(1020)\n","    # valid_sampler = torch.utils.data.sampler.SubsetRandomSampler(1020)\n","    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=shuffle)\n","    valid_loader = DataLoader(dataset=validation_dataset, batch_size=batch_size, shuffle=True)\n","    print(f\"Number of training examples: {len(train_dataset)}\")\n","    return (train_loader, valid_loader)\n","\n","train_loader, valid_loader = data_loader(data='flowers', batch_size=4, shuffle=True, test=False)\n","test_loader = data_loader(data='flowers', batch_size=4, shuffle=True, test=True)\n","# normalise = transforms.Normalize(mean=[0.4914,0.4822,0.4465],std=[0.2023,0.1994,0.2010])\n","# transform = transforms.Compose([transforms.Resize((224,224)),transforms.ToTensor(),normalise])\n","# transform_train = transforms.Compose(\n","#     [transforms.Resize((256,256)),\n","#      transforms.RandomHorizontalFlip(),\n","#      transforms.RandomVerticalFlip(p=0.5),\n","#      transforms.CenterCrop(224),\n","#      transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.4, hue=0.1),\n","#      transforms.RandomRotation(10),\n","# #      transforms.ToTensor(),\n","# #      normalise])\n","# train_dataset = datasets.Flowers102(root='./data', split=\"train\", download=True, transform=transform_train)\n","# validation_dataset = datasets.Flowers102(root=\"./data/\", split=\"val\", download=True, transform=transform)\n","# test = datasets.Flowers102(root=\"./data\", split=\"test\", download=True, transform=transform)\n","# train_loader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)\n","# valid_loader = DataLoader(dataset=validation_dataset, batch_size=32, shuffle=False)\n","# test_loader = DataLoader(dataset=test, batch_size=32, shuffle=False)\n"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"22oD_Lr345Fc","executionInfo":{"status":"ok","timestamp":1683398577209,"user_tz":-60,"elapsed":6,"user":{"displayName":"Bailey Uniacke","userId":"03860064819488115762"}}},"outputs":[],"source":["class Block(nn.Module):\n","    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n","        super(Block, self).__init__()\n","        self.conv1 = nn.Sequential(\n","            nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, stride=stride, padding=1, bias=False),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU()\n","        )\n","        self.conv2 = nn.Sequential(\n","            nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=3, stride=1, padding=1),\n","            nn.BatchNorm2d(out_channels)\n","        )\n","        self.downsample = downsample\n","        self.relu = nn.ReLU()\n","        self.out_channels = out_channels\n","    \n","    def forward(self, x):\n","        residual = x\n","        out = self.conv1(x)\n","        out = self.conv2(out)\n","        if self.downsample:\n","            residual = self.downsample(x)\n","        out += residual\n","        out = self.relu(out)\n","        return out"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"_-ndSLZn45Fd","executionInfo":{"status":"ok","timestamp":1683398577210,"user_tz":-60,"elapsed":6,"user":{"displayName":"Bailey Uniacke","userId":"03860064819488115762"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":4,"metadata":{"id":"HJpOotvg45Fe","executionInfo":{"status":"ok","timestamp":1683398577210,"user_tz":-60,"elapsed":5,"user":{"displayName":"Bailey Uniacke","userId":"03860064819488115762"}}},"outputs":[],"source":["class Rn(nn.Module):\n","    def __init__(self, block, layers, num_classes=102):\n","        super(Rn, self).__init__()\n","        self.in_planes = 64\n","        self.conv1 = nn.Sequential(\n","            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=7, stride=2, padding=3, bias=False),\n","            nn.BatchNorm2d(64),\n","            nn.ReLU()\n","        )\n","        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n","        self.layer0 = self._make_layer(block, 64, layers[0], stride=1)\n","        self.layer1 = self._make_layer(block, 128, layers[1], stride=2)\n","        self.layer2 = self._make_layer(block, 256, layers[2], stride=2)\n","        self.layer3 = self._make_layer(block, 512, layers[3], stride=2)\n","        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n","        self.fc = nn.Linear(512, num_classes)\n","    \n","    def _make_layer(self, block, planes, blocks, stride=1):\n","        downsample = None\n","        if stride != 1 or self.in_planes != planes:\n","            downsample = nn.Sequential(\n","                nn.Conv2d(in_channels=self.in_planes, out_channels=planes, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(planes)\n","            )\n","        layers = []\n","        layers.append(block(self.in_planes, planes, stride, downsample))\n","        self.in_planes = planes\n","        for i in range(1, blocks):\n","            layers.append(block(self.in_planes, planes))\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.maxpool(x)\n","        x = self.layer0(x)\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.avgpool(x)\n","        x = x.view(x.size(0),-1)\n","        x = self.fc(x)\n","        return x\n","    "]},{"cell_type":"code","execution_count":5,"metadata":{"id":"cxwREC8j45Ff","outputId":"e0fe9f9b-f8c3-4bf9-ea6d-efc46d67b741","colab":{"base_uri":"https://localhost:8080/","height":205},"executionInfo":{"status":"error","timestamp":1683398577661,"user_tz":-60,"elapsed":456,"user":{"displayName":"Bailey Uniacke","userId":"03860064819488115762"}}},"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-bbb4b6a39403>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcount_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"]}],"source":["def count_parameters(model)->int:\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","print(count_parameters(model))"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"EtytZDJr45Fg","executionInfo":{"status":"ok","timestamp":1683398600063,"user_tz":-60,"elapsed":1143,"user":{"displayName":"Bailey Uniacke","userId":"03860064819488115762"}}},"outputs":[],"source":["import requests\n","def post_discord(epoch,train_loss, val_accuracy):\n","    data = {\n","        \"username\": \"Flower Classifier\"\n","    }\n","    data[\"embeds\"] = [\n","        {\n","            \"title\": \"Epoch {} Results\".format(epoch),\n","            \"color\": 0x00ff00,\n","            \"fields\": [\n","                {\n","                    \"name\": \"Training Loss\",\n","                    \"value\": f\"{train_loss}\",\n","                    \"inline\": False\n","                },\n","                {\n","                    \"name\": \"Validation Accuracy\",\n","                    \"value\": f\"{val_accuracy}\",\n","                    \"inline\": False\n","                },\n","            ]\n","        }\n","    ]\n","    r = requests.post(\"https://discord.com/api/webhooks/1052587856343867392/SnR2U4HIdeF6ShECr0k1Mit6yrl3HgjtCMk_LykGD8eQ1qsZViY8HLeYsoBUXOHYfbgP\", json=data)\n","    print(r.status_code)\n"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"IgCHhSLD45Fh","executionInfo":{"status":"ok","timestamp":1683398602738,"user_tz":-60,"elapsed":2,"user":{"displayName":"Bailey Uniacke","userId":"03860064819488115762"}}},"outputs":[],"source":["import gc\n","\n","def train(model, config):\n","    if torch.cuda.is_available():\n","      if torch.cuda.device_count() > 1:\n","        model = nn.DataParallel(model)\n","    model.to(device)\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = torch.optim.SGD(model.parameters(), lr=config[\"learning_rate\"], momentum=0.9, weight_decay=config[\"weight_decay\"])\n","    for epoch in range(num_epochs):\n","        model.train()  # Set the model to training mode\n","        for i, (images, labels) in enumerate(train_loader):\n","            images = images.to(device)\n","            labels = labels.to(device)\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","            torch.cuda.empty_cache()\n","            gc.collect()\n","        \n","        print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))\n","        \n","        if epoch % print_every == 0:\n","            model.eval()  # Set the model to evaluation mode\n","            with torch.no_grad():\n","                correct = 0\n","                total = 0\n","                correctT = 0\n","                totalT = 0\n","                for images, labels in valid_loader:\n","                    images = images.to(device)\n","                    labels = labels.to(device)\n","                    outputs = model(images)\n","                    _, predicted = torch.max(outputs.data, 1)\n","                    total += labels.size(0)\n","                    correct += (predicted==labels).sum().item()\n","                for images, labels in train_loader:\n","                    images = images.to(device)\n","                    labels = labels.to(device)\n","                    outputs = model(images)\n","                    _, predicted = torch.max(outputs.data, 1)\n","                    totalT += labels.size(0)\n","                    correctT += (predicted==labels).sum().item()\n","\n","                print('Training Accuracy accross {} images: {} %'.format(totalT, 100 * correctT / totalT))\n","                print('Validation Accuracy accross {} images: {} %'.format(total, 100 * correct / total))\n","                #post_discord(epoch+1, '{:.4f}'.format(loss.item()), 100 * correct / total)\n","        total = 0\n","        correct = 0\n","        if epoch % 100 == 0 and epoch != 0:\n","            with torch.no_grad():\n","                for images, labels in test_loader:\n","                    images = images.to(device)\n","                    labels = labels.to(device)\n","                    outputs = model(images)\n","                    _, predicted = torch.max(outputs.data, 1)\n","                    total += labels.size(0)\n","                    correct += (predicted == labels).sum().item()\n","                    loss = criterion(outputs, labels)\n","                    val_loss += loss.cpu().numpy()\n","                    val_steps += 1\n","                    del images, labels, outputs\n","            torch.save(model.state_dict(), 'model-{}.pth'.format(100 * correct / total))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gj_kMo1745Fi","executionInfo":{"status":"aborted","timestamp":1683398577663,"user_tz":-60,"elapsed":11,"user":{"displayName":"Bailey Uniacke","userId":"03860064819488115762"}}},"outputs":[],"source":["torch.save(best.state_dict(), 'hey.pth')"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"K9rNSL2I45Fi","executionInfo":{"status":"ok","timestamp":1683398606565,"user_tz":-60,"elapsed":394,"user":{"displayName":"Bailey Uniacke","userId":"03860064819488115762"}}},"outputs":[],"source":["def test(model):\n","    with torch.no_grad():\n","        correct = 0\n","        total = 0\n","        for images, labels in test_loader:\n","            images = images.to(device)\n","            labels = labels.to(device)\n","            outputs = model(images)\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","            del images, labels, outputs\n","\n","        print('Accuracy of the network on the {} test images: {} %'.format(total, 100 * correct / total))   \n","        return correct / total\n"]},{"cell_type":"code","source":["num_classes = 102\n","print_every = 5\n","total_step = len(train_loader)\n","\n","bestModel = {\"learning_rate\": 0,\n","             \"weight_decay\": 0,\n","}\n","bestAccuracy = 0\n","\n","for trials in range (10):\n","    num_epochs = 40\n","    config = {\n","        \"learning_rate\": np.power(10, np.random.uniform(-5, -3)),\n","        \"weight_decay\": np.power(10, np.random.uniform(-5, -3)),\n","    }\n","    print(config)\n","    model = Rn(Block, [2,2,2,2], num_classes).to(device)\n","    train(model, config)\n","    acc = test(model)\n","    if acc > bestAccuracy:\n","        bestModel = config\n","        bestAccuracy = acc\n","\n","print(bestModel)\n","num_epochs = 300\n","model = Rn(Block, [2,2,2,2], num_classes).to(device)\n","train(model, bestModel)\n","test(model)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rZhyEck__QmZ","outputId":"e776dfc9-2750-4391-bd97-72e5b1d175d6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'learning_rate': 0.0006457388496865225, 'weight_decay': 7.712454304377741e-05}\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lur84xbu45Fj","executionInfo":{"status":"aborted","timestamp":1683398577664,"user_tz":-60,"elapsed":11,"user":{"displayName":"Bailey Uniacke","userId":"03860064819488115762"}}},"outputs":[],"source":["def count_parameters(model)->int:\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","print(count_parameters(model))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b0s7aSfm45Fj","executionInfo":{"status":"aborted","timestamp":1683398577665,"user_tz":-60,"elapsed":12,"user":{"displayName":"Bailey Uniacke","userId":"03860064819488115762"}}},"outputs":[],"source":["print(model)"]}],"metadata":{"kernelspec":{"display_name":"venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"orig_nbformat":4,"colab":{"provenance":[{"file_id":"1COyN9BsjDhkv0uCG18B9a755fn8jfR7g","timestamp":1683397971911}],"gpuType":"T4","toc_visible":true},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}